# Table Partitioning Check

Validates that large tables (>= 10M rows) are properly partitioned according to architecture guidelines.

## How to Fix

### For `large-unpartitioned`

Tables with >=25M rows must be partitioned to improve query performance, maintenance, and archival:

**Strategy 1: Range partitioning (for time-series data)**

```sql
-- Create partitioned table
CREATE TABLE sales_new (
  id bigint GENERATED BY DEFAULT AS IDENTITY,
  created_at timestamptz NOT NULL,
  customer_id bigint,
  PRIMARY KEY (id, created_at)
) PARTITION BY RANGE (created_at);

-- Create initial partitions
CREATE TABLE sales_2024_01 PARTITION OF sales_new
  FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');
CREATE TABLE sales_2024_02 PARTITION OF sales_new
  FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');
-- ... create partitions for each month

-- Migrate data (use pg_repack or manual batching)
-- See detailed migration guide below
```

**Strategy 2: List partitioning (for transient tables)**

See `transient-unpartitioned` fix below.

### For `transient-unpartitioned`

Transient tables (outbox, inbox, jobs) MUST use weekly partitioning with mod 4 for efficient cleanup:

```sql
-- Create partitioned outbox table
CREATE TABLE outbox_events (
  id bigint GENERATED BY DEFAULT AS IDENTITY,
  payload jsonb NOT NULL,
  created_at timestamptz NOT NULL DEFAULT now(),
  week_number int NOT NULL DEFAULT (EXTRACT(WEEK FROM now())::int % 4),
  PRIMARY KEY (id, week_number)
) PARTITION BY LIST (week_number);

-- Create 4 weekly partitions (mod 4)
CREATE TABLE outbox_events_w0 PARTITION OF outbox_events FOR VALUES IN (0);
CREATE TABLE outbox_events_w1 PARTITION OF outbox_events FOR VALUES IN (1);
CREATE TABLE outbox_events_w2 PARTITION OF outbox_events FOR VALUES IN (2);
CREATE TABLE outbox_events_w3 PARTITION OF outbox_events FOR VALUES IN (3);

-- Cleanup old data (TRUNCATE is much faster than DELETE)
-- Run weekly to truncate the oldest partition:
TRUNCATE TABLE outbox_events_w0;  -- Truncate partition for current week % 4
```

**Why mod 4 partitioning:**
- Rotates through 4 partitions (roughly monthly cleanup)
- TRUNCATE is instant, DELETE is slow on large tables
- Old data automatically dropped when partition is reused

### For `inefficient-partitions`

Individual partitions with >=25M rows indicate partition strategy needs adjustment:

**For time-based partitions (too wide):**
```sql
-- If yearly partitions are too large, switch to monthly:
-- 1. Create new monthly partitions
CREATE TABLE sales_2024_01 PARTITION OF sales
  FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

-- 2. Detach large yearly partition
ALTER TABLE sales DETACH PARTITION sales_2024;

-- 3. Move data to monthly partitions (batched)
INSERT INTO sales SELECT * FROM sales_2024 WHERE created_at >= '2024-01-01' AND created_at < '2024-02-01';
-- Repeat for each month

-- 4. Drop old partition after data migration
DROP TABLE sales_2024;
```

**For hash partitions (too few buckets):**
```sql
-- If using 4 hash partitions but still have large partitions, increase to 8 or 16
-- This requires recreating the table (plan carefully)
-- See: https://www.postgresql.org/docs/current/ddl-partitioning.html#DDL-PARTITIONING-DECLARATIVE-MAINTENANCE
```

## Subchecks

### large-unpartitioned

Identifies large business tables that are not partitioned.

**Standard Thresholds:**
- Warning: Tables with >= 25M rows not partitioned
- Critical: Tables with >= 50M rows not partitioned

**Activity-Aware Thresholds (lower for write-heavy tables):**
- Warning: Tables with >= 10M rows not partitioned
- Critical: Tables with >= 25M rows not partitioned

| Table Type | WARN | FAIL |
|------------|------|------|
| Regular | 25M rows | 50M rows |
| Insert-heavy (>80% inserts) | 10M rows | 25M rows |
| High-delete (>20% deletes/inserts) | 10M rows | 25M rows |

**Why activity-aware?** Write-heavy tables benefit more from partitioning:
- INSERT-heavy often means time-series data; partitions enable `DROP PARTITION` vs slow `DELETE`
- High insert rates cause B-tree page splits and index bloat
- More inserts = more dead tuples from subsequent updates/deletes requiring vacuum
- `TRUNCATE PARTITION` is instant vs `DELETE` which generates dead tuples

> **Note**: This check depends on PostgreSQL runtime statistics. For accurate activity ratios, statistics should be at least 7 days old. Run the `statistics-freshness` check to validate statistics maturity.

### transient-unpartitioned

Identifies large transient tables (outbox, inbox, jobs, queues) that are not partitioned.

**Detected table patterns (regex):**
- `outbox`, `inbox` - Event sourcing tables
- `_jobs`, `_job` - Background job tables
- `oban_*` - Oban job queue (Elixir)
- `logs` - Generic debug/log tables
- `events` - Event tables

**Required:** All large transient tables MUST be partitioned (FAIL severity).

### inefficient-partitions

Identifies individual partitions that have grown too large (>= 10M rows), indicating the partition strategy is ineffective.

**Common causes:**
- Time-based partitions are too wide (yearly instead of monthly)
- Hash partitions have too few buckets
- Uneven data distribution across partition keys

**Severity:** Warning - review and adjust the partitioning strategy.

## Architecture Guidelines

From the Database Architecture Guidelines:

> **MUST:** Partition tables that exceed or are expected to exceed 50 million rows.
> - Rationale: Improves query performance, enables more efficient maintenance, and facilitates data archiving.

> **SHOULD:** Use time-based range partitioning when applicable.
> - Rationale: Provides predictable partition sizes and simplifies data lifecycle management.

> **MUST:** Partition transient tables (outbox/inbox/jobs) per week mod 4, truncating old ones.
> - Rationale: TRUNCATE is vastly more efficient than DELETE for high-churn tables.

## Partitioning Strategies

### Range Partitioning (Recommended for time-series data)

```sql
CREATE TABLE sales (
  id bigint GENERATED BY DEFAULT AS IDENTITY,
  created_at timestamptz NOT NULL,
  customer_id bigint,
  PRIMARY KEY (id, created_at)
) PARTITION BY RANGE (created_at);

CREATE TABLE sales_2024_01 PARTITION OF sales
  FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');
```

### List Partitioning (Recommended for transient data)

```sql
CREATE TABLE outbox_events (
  id bigint GENERATED BY DEFAULT AS IDENTITY,
  payload jsonb NOT NULL,
  created_at timestamptz NOT NULL DEFAULT now(),
  week_number int NOT NULL DEFAULT (EXTRACT(WEEK FROM now())::int % 4),
  PRIMARY KEY (id, week_number)
) PARTITION BY LIST (week_number);

CREATE TABLE outbox_events_w0 PARTITION OF outbox_events FOR VALUES IN (0);
CREATE TABLE outbox_events_w1 PARTITION OF outbox_events FOR VALUES IN (1);
CREATE TABLE outbox_events_w2 PARTITION OF outbox_events FOR VALUES IN (2);
CREATE TABLE outbox_events_w3 PARTITION OF outbox_events FOR VALUES IN (3);
```

### Hash Partitioning (For even distribution without natural key)
Avoid using this one unless you _really_ know what you are doing.
It is easy to hit _all_ partitions if queries are not crafted carefully.

```sql
CREATE TABLE large_table (
  id bigint PRIMARY KEY,
  data jsonb
) PARTITION BY HASH (id);

CREATE TABLE large_table_p0 PARTITION OF large_table FOR VALUES WITH (MODULUS 4, REMAINDER 0);
CREATE TABLE large_table_p1 PARTITION OF large_table FOR VALUES WITH (MODULUS 4, REMAINDER 1);
CREATE TABLE large_table_p2 PARTITION OF large_table FOR VALUES WITH (MODULUS 4, REMAINDER 2);
CREATE TABLE large_table_p3 PARTITION OF large_table FOR VALUES WITH (MODULUS 4, REMAINDER 3);
```

## Learning Resources

### Introductory Tutorials

- [How to Use Table Partitioning to Scale PostgreSQL - Practical guide][1]
- [PostgreSQL Table Partitioning - Official docs][2]

## Tools

- **pg_partman**: Automated partition creation and maintenance
- **pg_repack**: Online table reorganization for converting existing tables


[1]: https://www.enterprisedb.com/postgres-tutorials/how-use-table-partitioning-scale-postgresql
[2]: https://www.postgresql.org/docs/current/ddl-partitioning.html